{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.368816\n",
      "Learning rate after iteration 0: 0.000200\n",
      "Cost after iteration 1000: 0.688173\n",
      "Learning rate after iteration 1000: 0.000200\n",
      "Cost after iteration 2000: 0.570295\n",
      "Learning rate after iteration 2000: 0.000200\n",
      "Cost after iteration 3000: 0.456534\n",
      "Learning rate after iteration 3000: 0.000200\n",
      "Cost after iteration 4000: 0.410062\n",
      "Learning rate after iteration 4000: 0.000200\n",
      "Cost after iteration 5000: 0.380939\n",
      "Learning rate after iteration 5000: 0.000200\n",
      "Cost after iteration 6000: 0.358900\n",
      "Learning rate after iteration 6000: 0.000200\n",
      "Cost after iteration 7000: 0.340171\n",
      "Learning rate after iteration 7000: 0.000200\n",
      "Cost after iteration 8000: 0.324200\n",
      "Learning rate after iteration 8000: 0.000200\n",
      "Cost after iteration 9000: 0.279655\n",
      "Learning rate after iteration 9000: 0.000200\n",
      "Cost after iteration 10000: 0.268023\n",
      "Learning rate after iteration 10000: 0.000200\n",
      "Cost after iteration 11000: 0.254734\n",
      "Learning rate after iteration 11000: 0.000200\n",
      "Cost after iteration 12000: 0.247427\n",
      "Learning rate after iteration 12000: 0.000200\n",
      "Cost after iteration 13000: 0.239802\n",
      "Learning rate after iteration 13000: 0.000200\n",
      "Cost after iteration 14000: 0.233186\n",
      "Learning rate after iteration 14000: 0.000200\n",
      "Cost after iteration 15000: 0.227877\n",
      "Learning rate after iteration 15000: 0.000200\n",
      "Cost after iteration 16000: 0.223282\n",
      "Learning rate after iteration 16000: 0.000200\n",
      "Cost after iteration 17000: 0.219179\n",
      "Learning rate after iteration 17000: 0.000200\n",
      "Cost after iteration 18000: 0.215508\n",
      "Learning rate after iteration 18000: 0.000200\n",
      "Cost after iteration 19000: 0.212228\n",
      "Learning rate after iteration 19000: 0.000200\n",
      "Cost after iteration 20000: 0.209262\n",
      "Learning rate after iteration 20000: 0.000200\n",
      "Cost after iteration 21000: 0.205485\n",
      "Learning rate after iteration 21000: 0.000190\n",
      "Cost after iteration 22000: 0.202412\n",
      "Learning rate after iteration 22000: 0.000182\n",
      "Cost after iteration 23000: 0.199609\n",
      "Learning rate after iteration 23000: 0.000174\n",
      "Cost after iteration 24000: 0.196750\n",
      "Learning rate after iteration 24000: 0.000167\n",
      "Cost after iteration 25000: 0.194012\n",
      "Learning rate after iteration 25000: 0.000160\n",
      "Cost after iteration 26000: 0.191593\n",
      "Learning rate after iteration 26000: 0.000154\n",
      "Cost after iteration 27000: 0.189442\n",
      "Learning rate after iteration 27000: 0.000148\n",
      "Cost after iteration 28000: 0.187498\n",
      "Learning rate after iteration 28000: 0.000143\n",
      "Cost after iteration 29000: 0.185716\n",
      "Learning rate after iteration 29000: 0.000138\n",
      "Cost after iteration 30000: 0.184062\n",
      "Learning rate after iteration 30000: 0.000133\n",
      "Cost after iteration 31000: 0.182507\n",
      "Learning rate after iteration 31000: 0.000129\n",
      "Cost after iteration 32000: 0.181025\n",
      "Learning rate after iteration 32000: 0.000125\n",
      "Cost after iteration 33000: 0.179597\n",
      "Learning rate after iteration 33000: 0.000121\n",
      "Cost after iteration 34000: 0.178211\n",
      "Learning rate after iteration 34000: 0.000118\n",
      "Cost after iteration 35000: 0.176861\n",
      "Learning rate after iteration 35000: 0.000114\n",
      "Cost after iteration 36000: 0.175539\n",
      "Learning rate after iteration 36000: 0.000111\n",
      "Cost after iteration 37000: 0.174235\n",
      "Learning rate after iteration 37000: 0.000108\n",
      "Cost after iteration 38000: 0.172941\n",
      "Learning rate after iteration 38000: 0.000105\n",
      "Cost after iteration 39000: 0.171650\n",
      "Learning rate after iteration 39000: 0.000103\n",
      "Cost after iteration 40000: 0.170414\n",
      "Learning rate after iteration 40000: 0.000100\n",
      "Cost after iteration 41000: 0.169627\n",
      "Learning rate after iteration 41000: 0.000098\n",
      "Cost after iteration 42000: 0.168908\n",
      "Learning rate after iteration 42000: 0.000095\n",
      "Cost after iteration 43000: 0.168223\n",
      "Learning rate after iteration 43000: 0.000093\n",
      "Cost after iteration 44000: 0.167569\n",
      "Learning rate after iteration 44000: 0.000091\n",
      "Cost after iteration 45000: 0.166944\n",
      "Learning rate after iteration 45000: 0.000089\n",
      "Cost after iteration 46000: 0.166343\n",
      "Learning rate after iteration 46000: 0.000087\n",
      "Cost after iteration 47000: 0.165766\n",
      "Learning rate after iteration 47000: 0.000085\n",
      "Cost after iteration 48000: 0.165211\n",
      "Learning rate after iteration 48000: 0.000083\n",
      "Cost after iteration 49000: 0.164675\n",
      "Learning rate after iteration 49000: 0.000082\n",
      "Accuracy on training set: 94.02%\n",
      "On training set:\n",
      "True Positive:   159\n",
      "True Negative:   234\n",
      "False Negative:   17\n",
      "False Positive:   8\n",
      "True Positive Rate / Recall: 90.34%\n",
      "Precision: 95.21%\n",
      "False Positive Rate / Fallout: 3.31%\n",
      "Accuracy on test set: 89.93%\n",
      "On Test set:\n",
      "True Positive:   31\n",
      "True Negative:   103\n",
      "False Negative:   4\n",
      "False Positive:   11\n",
      "True Positive Rate / Recall: 88.57%\n",
      "Precision: 73.81%\n",
      "False Positive Rate / Fallout: 9.65%\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Shallow Neural net with only one hidden layer\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    train_x = pd.read_csv(\"cancer_data.csv\")\n",
    "    train_x = np.array(train_x)\n",
    "    train_y = pd.read_csv(\"cancer_data_y.csv\")\n",
    "    train_y = np.array(train_y)\n",
    "\n",
    "    d = model(train_x.T, train_y.T, n_h=20, num_iters=50000, alpha=0.0002, print_cost=True)\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    s = 1 / (1 + np.exp(-z))\n",
    "    return s\n",
    "\n",
    "\n",
    "def layers(X, Y):\n",
    "    \"\"\"\n",
    "\n",
    "    :param X:\n",
    "    :param Y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    n_x = X.shape[0]\n",
    "    n_y = Y.shape[0]\n",
    "    return n_x, n_y\n",
    "\n",
    "\n",
    "def initialize(n_x, n_h, n_y):\n",
    "    \"\"\"\n",
    "\n",
    "    :param n_x:\n",
    "    :param n_h:\n",
    "    :param n_y:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    np.random.seed(2)\n",
    "    W1 = np.random.randn(n_h, n_x) * 0.01\n",
    "    b1 = np.random.rand(n_h, 1)\n",
    "    W2 = np.random.rand(n_y, n_h)\n",
    "    b2 = np.random.rand(n_y, 1)\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def forward_prop(X, parameters):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = sigmoid(Z2)\n",
    "\n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2}\n",
    "\n",
    "    return A2, cache\n",
    "\n",
    "\n",
    "def compute_cost(A2, Y, parameters):\n",
    "    m = Y.shape[1]\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    #We know that Loss L is mathematically defined as: l(y^,y)=-[ylogy^+(1-y)log(1-y^)]\n",
    "    logprobs = np.multiply(np.log(A2), Y) + np.multiply(np.log(1 - A2), (1 - Y))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = np.squeeze(cost)\n",
    "\n",
    "    return cost\n",
    "\n",
    "\n",
    "def back_prop(parameters, cache, X, Y):\n",
    "    m = Y.shape[1]\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "\n",
    "    dZ2 = A2 - Y\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.square(A1))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "\n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2}\n",
    "\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_params(parameters, grads, alpha):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "#w=w â€” alpha * |dE/dw|\n",
    "    W1 = W1 - alpha * dW1\n",
    "    b1 = b1 - alpha * db1\n",
    "    W2 = W2 - alpha * dW2\n",
    "    b2 = b2 - alpha * db2\n",
    "\n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2}\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def model(X, Y, n_h, num_iters, alpha, print_cost):\n",
    "    np.random.seed(3)\n",
    "    n_x = layers(X, Y)[0]\n",
    "    n_y = layers(X, Y)[1]\n",
    "\n",
    "    parameters = initialize(n_x, n_h, n_y)\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "\n",
    "    costs = []\n",
    "    for i in range(0, num_iters):\n",
    "\n",
    "        A2, cache = forward_prop(X, parameters)\n",
    "\n",
    "        cost = compute_cost(A2, Y, parameters)\n",
    "        grads = back_prop(parameters, cache, X, Y)\n",
    "        if (i > 20000):\n",
    "            alpha1 = (20000 / i) * alpha\n",
    "            parameters = update_params(parameters, grads, alpha1)\n",
    "        else:\n",
    "            parameters = update_params(parameters, grads, alpha)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print(\"Cost after iteration %i: %f\" % (i, cost))\n",
    "            if i <= 20000:\n",
    "                print(\"Learning rate after iteration %i: %f\" % (i, alpha))\n",
    "            else:\n",
    "                print(\"Learning rate after iteration %i: %f\" % (i, alpha1))\n",
    "\n",
    "    X_test = pd.read_csv(\"test_cancer_data.csv\")\n",
    "    X_test = np.array(X_test)\n",
    "    X_test = X_test.T\n",
    "    Y_test = pd.read_csv(\"test_cancer_data_y.csv\")\n",
    "    Y_test = np.array(Y_test)\n",
    "    Y_test = Y_test.T\n",
    "\n",
    "    predictions = predict(parameters, X)\n",
    "    print('Accuracy on training set: %.2f' % float(\n",
    "        (np.dot(Y, predictions.T) + np.dot(1 - Y, 1 - predictions.T)) / float(Y.size) * 100) + '%')\n",
    "    truePositive = 0\n",
    "    trueNegative = 0\n",
    "    falseNegative = 0\n",
    "    falsePositive = 0\n",
    "    predList = predictions.tolist()\n",
    "    tlist = Y.tolist()\n",
    "\n",
    "    array_length = len(predList[0])\n",
    "    for i in range(array_length):\n",
    "        if predList[0][i] == 1 and tlist[0][i] == 1:\n",
    "            truePositive += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 0:\n",
    "            trueNegative += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 1:\n",
    "            falseNegative += 1\n",
    "        elif predList[0][i] == 1 and tlist[0][i] == 0 :\n",
    "            falsePositive += 1\n",
    "        else:\n",
    "            print(predList[0][i])\n",
    "            print(tlist[0][i])\n",
    "            print(\"WTF\")\n",
    "    tpr = truePositive / (truePositive + falseNegative) * 100\n",
    "    fpr = falsePositive / (falsePositive + trueNegative) * 100\n",
    "    precision = truePositive / (truePositive + falsePositive) * 100\n",
    "    print(\"On training set:\\nTrue Positive:  \", truePositive)\n",
    "    print(\"True Negative:  \", trueNegative)\n",
    "    print(\"False Negative:  \", falseNegative)\n",
    "    print(\"False Positive:  \", falsePositive)\n",
    "    print(\"True Positive Rate / Recall: %.2f\" % tpr+str('%'))\n",
    "    print(\"Precision: %.2f\" %precision+str('%'))\n",
    "    print(\"False Positive Rate / Fallout: %.2f\" %fpr+str('%'))\n",
    "\n",
    "    predictions = predict(parameters, X_test)\n",
    "    print('Accuracy on test set: %.2f' % float(\n",
    "        (np.dot(Y_test, predictions.T) + np.dot(1 - Y_test, 1 - predictions.T)) / float(Y_test.size) * 100) + '%')\n",
    "    truePositive = 0\n",
    "    trueNegative = 0\n",
    "    falseNegative = 0\n",
    "    falsePositive = 0\n",
    "    predList = predictions.tolist()\n",
    "    tlist = Y_test.tolist()\n",
    "\n",
    "    assert (len(predictions[0])== len(tlist[0]))\n",
    "    array_length = len(predList[0])\n",
    "    for i in range(array_length):\n",
    "        if predList[0][i] == 1 and tlist[0][i] == 1:\n",
    "            truePositive += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 0:\n",
    "            trueNegative += 1\n",
    "        elif predList[0][i] == 0 and tlist[0][i] == 1:\n",
    "            falseNegative += 1\n",
    "        elif predList[0][i] == 1 and tlist[0][i] == 0 :\n",
    "            falsePositive += 1\n",
    "        else:\n",
    "            print(predList[0][i])\n",
    "            print(tlist[0][i])\n",
    "            print(\"WTF\")\n",
    "    tpr = truePositive / (truePositive + falseNegative) * 100\n",
    "    fpr = falsePositive / (falsePositive + trueNegative) * 100\n",
    "    precision = truePositive / (truePositive + falsePositive) * 100\n",
    "    print(\"On Test set:\\nTrue Positive:  \", truePositive)\n",
    "    print(\"True Negative:  \", trueNegative)\n",
    "    print(\"False Negative:  \", falseNegative)\n",
    "    print(\"False Positive:  \", falsePositive)\n",
    "    print(\"True Positive Rate / Recall: %.2f\" % tpr+str('%'))\n",
    "    print(\"Precision: %.2f\" %precision+str('%'))\n",
    "    print(\"False Positive Rate / Fallout: %.2f\" %fpr+str('%'))\n",
    "\n",
    "    plt.plot(costs)\n",
    "    plt.ylabel('cost')\n",
    "    plt.xlabel('iterations (per hundreds)')\n",
    "    plt.title(\"Learning rate =\" + str(alpha))\n",
    "    plt.show()\n",
    "\n",
    "    return parameters\n",
    "\n",
    "# predictions =  yprediction=1{activation > 0.5}={1 if activation>0.5 , 0 otherwise\n",
    "## Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "def predict(parameters, X):\n",
    "    A2, cache = forward_prop(X, parameters)\n",
    "    predictions = np.round(A2)\n",
    "\n",
    "    return predictions\n",
    "\n",
    "\n",
    "main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
